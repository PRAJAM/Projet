{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau de Répartition des Bandes de Fréquence\n",
    "## Projet Mastercamp Data\n",
    "\n",
    "Pierre Bonnin\n",
    "\n",
    "Romain Caussignac\n",
    "\n",
    "Antoine Combaldieu\n",
    "\n",
    "Alice Guillou\n",
    "\n",
    "Mehdy Michalak\n",
    "\n",
    "Jules Sucrot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation et nettoyage de la Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "import streamlit as st\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/PRAJAM/Projet/raw/jules/Export_TER_juin2023_FIX_SafwanChendeb.csv\",sep=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlever les valeurs nulles ou trop petites de Largeur de bande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna(subset=['ASS_LGBD_KHZ'])\n",
    "df2 = df2[df2[\"ASS_LGBD_KHZ\"] >1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlever les antennes qui ont été supprimées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enreg_to_supp = df2[df2['MVT_CODE'] == 'SUP']['N° ENREG']\n",
    "df2 = df2[~df2['N° ENREG'].isin(enreg_to_supp)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garder seulement les ajouts d'antenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2  = df2[df2['MVT_CODE'] == 'ADD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlever les MOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['MVT_CODE'] != 'MOD' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Garder seulement les dernières modifications de chaque antenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date CAF'] = pd.to_datetime(df['Date CAF'], format='%d/%m/%Y')\n",
    "df2 = df2.sort_values('Date CAF').drop_duplicates(subset = \"N° ENREG\", keep = 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Échantillonage des données (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fraction = 0.1  \n",
    "df = df.sample(frac=sample_fraction, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph du nombre d'antennes ajoutées par mois et du nombre d'antennes en service par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title(\"Analyse des Antennes\")\n",
    "\n",
    "enreg_to_supp = df2[df2['MVT_CODE'] == 'SUP']['N° ENREG']\n",
    "df2 = df2[~df2['N° ENREG'].isin(enreg_to_supp)]\n",
    "df2 = df2[df2['MVT_CODE'] == 'ADD']\n",
    "df2 = df2[df2['MVT_CODE'] != 'MOD' ]\n",
    "df2['Date CAF'] = pd.to_datetime(df['Date CAF'], format='%d/%m/%Y')\n",
    "df2 = df2.sort_values('Date CAF').drop_duplicates(subset = \"N° ENREG\", keep = 'last')\n",
    "df2['YearMonth'] = df2['Date CAF'].dt.to_period('M')\n",
    "monthly_counts = df2['YearMonth'].value_counts().sort_index().reset_index()\n",
    "monthly_counts.columns = ['YearMonth', 'Number of Antennas']\n",
    "\n",
    "monthly_counts['YearMonth'] = monthly_counts['YearMonth'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot du graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph du nombre d'antennes en service par mois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un nouveau Dataframe pour les données des antennes par mois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Date CAF'] = pd.to_datetime(df2['Date CAF'], format='%d/%m/%Y')\n",
    "df2 = df2.sort_values(by='Date CAF')\n",
    "df2['YearMonth'] = df2['Date CAF'].dt.to_period('M')\n",
    "\n",
    "adds_per_month = df2[df2['MVT_CODE'] == 'ADD'].groupby('YearMonth').size()\n",
    "sups_per_month = df2[df2['MVT_CODE'] == 'SUP'].groupby('YearMonth').size()\n",
    "service_df_corrected = pd.DataFrame({'Adds': adds_per_month, 'Sups': sups_per_month}).fillna(0)\n",
    "service_df_corrected['Cumulative Adds'] = service_df_corrected['Adds'].cumsum()\n",
    "service_df_corrected['Cumulative Sups'] = service_df_corrected['Sups'].cumsum()\n",
    "service_df_corrected['Antennas in Service'] = service_df_corrected['Cumulative Adds'] - service_df_corrected['Cumulative Sups']\n",
    "service_df_corrected = service_df_corrected.reset_index()\n",
    "service_df_corrected['YearMonth'] = service_df_corrected['YearMonth'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traçage de la figure avec plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 03:30:12.847 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\sucro\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.title(\"Analyse des Antennes\")\n",
    "\n",
    "fig = px.line(\n",
    "    monthly_counts, \n",
    "    x='YearMonth', \n",
    "    y='Number of Antennas', \n",
    "    title='Évolution du nombre d\\'ajout d\\'antennes par mois',\n",
    "    markers=True,\n",
    "    labels={'YearMonth': 'Mois', 'Number of Antennas': 'Nombre d\\'antennes ajoutées'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Mois',\n",
    "    yaxis_title='Nombre d\\'antennes ajoutées',\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "st.plotly_chart(fig)\n",
    "\n",
    "fig_corrected = px.line(\n",
    "    service_df_corrected, \n",
    "    x='YearMonth', \n",
    "    y='Antennas in Service', \n",
    "    title='Nombre d\\'antennes en service par mois',\n",
    "    markers=True,\n",
    "    labels={'YearMonth': 'Mois', 'Antennas in Service': 'Nombre d\\'antennes en service'}\n",
    ")\n",
    "\n",
    "fig_corrected.update_layout(\n",
    "    xaxis_title='Mois',\n",
    "    yaxis_title='Nombre d\\'antennes en service',\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "st.plotly_chart(fig_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conversion des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction vectorisée pour convertir les coordonnées DMS en degrés décimaux\n",
    "def dms_to_dd(degrees, minutes, seconds, orientation):\n",
    "    dd = degrees + minutes / 60 + seconds / 3600\n",
    "    dd[orientation.isin(['W', 'S'])] *= -1\n",
    "    return dd\n",
    "\n",
    "# Appliquer la conversion sur les colonnes de latitude et de longitude\n",
    "df2['latitude'] = dms_to_dd(df2['PT_LAT_DEG'], df2['PT_LAT_MIN'], df2['PT_LAT_SEC'], df2['PT_LAT_ORIENT'])\n",
    "df2['longitude'] = dms_to_dd(df2['PT_LONG_DEG'], df2['PT_LONG_MIN'], df2['PT_LONG_SEC'], df2['PT_LONG_ORIENT'])\n",
    "\n",
    "#drop\n",
    "df2 = df2.drop(['PT_LAT_DEG', 'PT_LAT_MIN', 'PT_LAT_SEC', 'PT_LAT_ORIENT', 'PT_LONG_DEG', 'PT_LONG_MIN', 'PT_LONG_SEC', 'PT_LONG_ORIENT', 'BASE', 'MVT_CODE', 'N° ENREG', 'TER_ANT_ANG', 'TER_ANT_AZM_MAX'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "suppresion des valeurs aberrantes et inutiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop ass_frq > 100 000 000\n",
    "df2 = df2[df2['ASS_FRQ_KHZ'] < 50000000]\n",
    "\n",
    "\n",
    "#drop ass_lgbd > 200 000\n",
    "df2 = df2[df2['ASS_LGBD_KHZ'] < 200000]\n",
    "\n",
    "#encadrer la longitude et latitude : 51.691467, -6.106181 et 41.924975, 8.307881\n",
    "df2 = df2[(df2['latitude'] >= 41.924975) & (df2['latitude'] <= 51.691467) & (df2['longitude'] >= -6.106181) & (df2['longitude'] <= 8.307881)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map des antennes en France par année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.cache_data\n",
    "def get_df_by_year(df_sorted):\n",
    "    df_by_year = {}\n",
    "    for year in df_sorted['Annee'].unique():\n",
    "        current_year_rows = df_sorted[(df_sorted['Annee'] == year) & (df_sorted['MVT_CODE'].isin(['ADD', 'MOD']))]\n",
    "        previous_years_rows = df_sorted[(df_sorted['Annee'] < year) & (~df_sorted['MVT_CODE'].str.contains('SUP', na=False))]\n",
    "        combined_rows = pd.concat([previous_years_rows, current_year_rows])\n",
    "        df_by_year[year] = combined_rows\n",
    "    return df_by_year\n",
    "\n",
    "df_sorted = df2()\n",
    "df_by_year = get_df_by_year(df_sorted)\n",
    "\n",
    "# Afficher la carte dans Streamlit\n",
    "st.title('Carte des antennes avec HeatMap et clusters par année')\n",
    "\n",
    "selected_year = st.selectbox(\"Sélectionner une année\", df_sorted['Annee'].unique())\n",
    "df_year = df_by_year[selected_year]\n",
    "\n",
    "# Échantillonnage des données pour réduire le nombre de points\n",
    "sample_fraction = 0.1  # Vous pouvez ajuster cette valeur\n",
    "df_sample = df_year.sample(frac=sample_fraction, random_state=1)\n",
    "\n",
    "# Créer une carte Folium centrée sur la France avec des tuiles légères\n",
    "m = folium.Map(location=[46.603354, 1.888334], zoom_start=6, tiles='CartoDB positron')\n",
    "\n",
    "# Ajouter des clusters de points pour une meilleure visualisation\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Ajouter les points au cluster\n",
    "for idx, row in df_sample.iterrows():\n",
    "    folium.Marker(location=[row['latitude'], row['longitude']]).add_to(marker_cluster)\n",
    "\n",
    "# Préparer les données pour le HeatMap avec intensité\n",
    "heat_data = [[row['latitude'], row['longitude'], 1] for index, row in df_sample.iterrows()]\n",
    "\n",
    "# Ajouter le HeatMap à la carte avec des paramètres ajustés pour une meilleure performance et visibilité\n",
    "HeatMap(heat_data, radius=15, blur=10, max_zoom=12, min_opacity=0.4).add_to(m)\n",
    "\n",
    "# Afficher la carte dans Streamlit\n",
    "st_folium(m, width=800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largeur de bande et services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir 'ASS_FRQ_KHZ' et 'ASS_LGBD_KHZ' en entiers si ce sont des floats\n",
    "df2['ASS_FRQ_KHZ'] = df2['ASS_FRQ_KHZ'].astype(int)\n",
    "df2['ASS_LGBD_KHZ'] = df2['ASS_LGBD_KHZ'].astype(int)\n",
    "\n",
    "# Ajouter une colonne pour la bande de fréquence en MHz\n",
    "df2['ASS_FRQ_MHZ'] = df2['ASS_FRQ_KHZ'] / 1000\n",
    "df2['ASS_LGBD_MHZ'] = df2['ASS_LGBD_KHZ'] / 1000\n",
    "\n",
    "# Ajouter une colonne pour la fréquence de fin en MHz\n",
    "df2['END_FRQ_MHZ'] = df2['ASS_FRQ_MHZ'] + df2['ASS_LGBD_MHZ']\n",
    "\n",
    "# Regrouper les données par année, service (Code CAF) et affectataire (BASE)\n",
    "df2['Year'] = df2['Date CAF'].dt.year\n",
    "grouped = df2.groupby(['Year', 'Code CAF', 'BASE']).agg(\n",
    "    {'ASS_FRQ_MHZ': 'count', 'ASS_LGBD_MHZ': 'sum'}\n",
    ").reset_index()\n",
    "\n",
    "# Renommer les colonnes pour plus de clarté\n",
    "grouped.columns = ['Year', 'Service', 'Affectataire', 'Num_Bands', 'Total_Bandwidth_MHz']\n",
    "\n",
    "fig_bar = px.bar(grouped, x='Year', y='Total_Bandwidth_MHz', color='Service', barmode='stack',\n",
    "             hover_data=['Affectataire', 'Num_Bands'],\n",
    "             title='Largeur de Bande Totale par Année et par Service/Affectataire')\n",
    "\n",
    "fig_bar.update_layout(xaxis=dict(tickformat='d'), yaxis=dict(tickformat=','))\n",
    "st.plotly_chart(fig_bar)\n",
    "\n",
    "fig_pie = px.pie(grouped, values='Total_Bandwidth_MHz', names='Service', title='Répartition de la Largeur de Bande par Service')\n",
    "st.plotly_chart(fig_pie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# Sélection des colonnes numériques et non numériques\n",
    "numerical_cols = ['ASS_FRQ_KHZ', 'ASS_LGBD_KHZ',\n",
    "                  'latitude', 'longitude']\n",
    "categorical_cols = ['Code CAF']  # Exemple de colonnes catégorielles à encoder\n",
    "\n",
    "\n",
    "# Encodage des colonnes catégorielles\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_encoded = df2.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df_encoded[col] = label_encoder.fit_transform(df_encoded[col])\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_standardized = df_encoded.copy()\n",
    "\n",
    "df_standardized[numerical_cols] = scaler.fit_transform(df_standardized[numerical_cols])\n",
    "df_standardized[categorical_cols] = scaler.fit_transform(df_standardized[categorical_cols])\n",
    "df_standardized['Date CAF'] = scaler.fit_transform(df_standardized[['Date CAF']])\n",
    "df_standardized['Code CAF'] /= 3\n",
    "df_standardized['Date CAF'] /= 2\n",
    "df_standardized['Date CAF'] +=1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot each column\n",
    "df_standardized.boxplot(figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de corrélation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrice de correlation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = df_standardized.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "wcss = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(df_standardized)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Tracé du coude (Elbow Method)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
    "plt.xlabel('Nombre de Clusters')\n",
    "plt.ylabel('WCSS (Inertia)')\n",
    "plt.title('Méthode du Coude pour K-Means')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized.head()\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#kmeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(df_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplot each attribute with clusters\n",
    "df_standardized['cluster'] = kmeans.labels_\n",
    "df_standardized.boxplot(by='cluster', figsize=(12, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter df plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter(df2, x='Date CAF', y='ASS_FRQ_KHZ', color=\"Code CAF\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter df plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter(df2, x='Date CAF', y='ASS_FRQ_KHZ', color=kmeans.labels_)\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn classification for code caf\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the features and target variables\n",
    "X = df_standardized[['ASS_FRQ_KHZ', 'ASS_LGBD_KHZ', 'longitude', 'latitude', 'Date CAF']]\n",
    "y = df2['Code CAF']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the KNN classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#f1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "#y_pred against y_test heat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest pour predir la frequence\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the features and target variables\n",
    "X = df_standardized[['ASS_LGBD_KHZ', 'longitude', 'latitude', 'Date CAF']]\n",
    "y = df2['ASS_FRQ_KHZ']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the Random Forest regressor\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Mean Squared Error:', mse)\n",
    "\n",
    "# Feature importance\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances\n",
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "#plot ypred against y test\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
